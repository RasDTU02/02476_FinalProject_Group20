Categorized Tasks:

Version Control and Environment Setup  RASMUS
Task 1: Create a Git repository (M5).
Task 2: Ensure all team members have write access to the GitHub repository (M5).
Task 3: Create a dedicated environment for the project to track packages (M2).
Task 10: Set up version control for your data or part of your data (M8).
Task 27: Add pre-commit hooks to your version control setup (M18).

Project Initialization BJØRN
Task 4: Create the initial file structure using cookiecutter with an appropriate template (M6).
Task 5: Fill out the data.py file to download and preprocess data (if necessary) (M6).
Task 6: Add a model to model.py and a training procedure to train.py (M6).
Task 7: Fill out requirements.txt and requirements_dev.txt (M2+M6). GØRES TIL SIDST.

Code and Good Practices ALEXANDER
Task 8: Comply with good coding practices (pep8) (M7).
Task 9: Use code typing and document essential parts of the code (M7).
Task 24: Set up continuous integration on GitHub (M17).
Task 26: Add a linting step to your continuous integration (M17).

Command Line Interface and Automation ALEXANDER
Task 11: Add command-line interfaces and project commands where relevant (M9).
Task 28: Add a workflow that triggers when data changes (M19).
Task 29: Add a workflow that triggers on changes to the model registry (M19).

Docker and Deployment ALEXANDER AND RASMUS
Task 12: Construct Dockerfiles for your code (M10).
Task 13: Build and validate Dockerfiles locally (M10).
Task 34: Deploy the model in GCP using Functions or Run as backend (M23).

Experiment Management and Logging BJØRN
Task 14: Write configuration files for experiments (M11).
Task 15: Use Hydra to manage hyperparameters (M11).
Task 17: Use logging to record important events (M14).
Task 18: Use Weights & Biases for training progress (M14).
Task 19: Consider running a hyperparameter optimization sweep (M14).

Testing and Continuous Integration
Task 21: Write unit tests for data-related code (M16).
Task 22: Write unit tests for model and training procedures (M16).
Task 23: Calculate code coverage (M16).
Task 25: Add caching and multi-OS/Python/PyTorch testing to continuous integration (M17).
Task 35: Write API tests and add CI for these tests (M24).

Cloud and Scalability
Task 30: Set up a GCP bucket and link it with your data version control setup (M21).
Task 31: Create a trigger for automatic Docker image builds (M21).
Task 32: Train the model in GCP using Engine or Vertex AI (M21).
Task 44: Optimize data loading with distributed data loading (M29).
Task 45: Use distributed training to optimize your training pipeline (M30).

API and Frontend
Task 33: Create a FastAPI application for model inference (M22).
Task 36: Load test the API (M24).
Task 37: Create a specialized ML-deployment API (e.g., with ONNX or BentoML) (M25).
Task 38: Develop a frontend for your API (M26).

Monitoring and Optimization
Task 39: Check the model’s robustness to data drift (M27).
Task 40: Deploy a drift detection API in the cloud (M27).
Task 41: Add system metrics instrumentation to the API (M28).
Task 42: Set up cloud monitoring for the instrumented application (M28).
Task 43: Create alert systems in GCP for app behavior issues (M28).
Task 46: Use quantization, pruning, or compilation to improve inference speed (M31).

Documentation and Finalization TORSDAG d. 23 Januar
Task 47: Write documentation for the application (M32).
Task 48: Publish the documentation to GitHub Pages (M32).
Task 49: Revisit and reflect on the initial project description.
Task 50: Create an architectural diagram of the MLOps pipeline.
Task 51: Ensure all group members understand all project parts.
Task 52: Upload the completed project to GitHub.










Week 1 tasks

1. Create a git repository (M5)
2. Make sure that all team members have write access to the GitHub repository (M5)
3. Create a dedicated environment for you project to keep track of your packages (M2)
4. Create the initial file structure using cookiecutter with an appropriate template (M6)
5. Fill out the data.py file such that it downloads whatever data you need and preprocesses it (if necessary) (M6)
6. Add a model to model.py and a training procedure to train.py and get that running (M6)
7. Remember to fill out the requirements.txt and requirements_dev.txt file with whatever dependencies that you are using (M2+M6)
8. Remember to comply with good coding practices (pep8) while doing the project (M7)
9. Do a bit of code typing and remember to document essential parts of your code (M7)
10. Setup version control for your data or part of your data (M8)
11. Add command line interfaces and project commands to your code where it makes sense (M9)
12. Construct one or multiple docker files for your code (M10)
13. Build the docker files locally and make sure they work as intended (M10)
14. Write one or multiple configurations files for your experiments (M11)
15. Used Hydra to load the configurations and manage your hyperparameters (M11)
16. Use profiling to optimize your code (M12)
17. Use logging to log important events in your code (M14)
18. Use Weights & Biases to log training progress and other important metrics/artifacts in your code (M14)
19. Consider running a hyperparameter optimization sweep (M14)
20. Use PyTorch-lightning (if applicable) to reduce the amount of boilerplate in your code (M15)

Week 2 tasks

21. Write unit tests related to the data part of your code (M16)
22. Write unit tests related to model construction and or model training (M16)
23. Calculate the code coverage (M16)
24. Get some continuous integration running on the GitHub repository (M17)
25. Add caching and multi-os/python/pytorch testing to your continuous integration (M17)
26. Add a linting step to your continuous integration (M17)
27. Add pre-commit hooks to your version control setup (M18)
28. Add a continues workflow that triggers when data changes (M19)
29. Add a continues workflow that triggers when changes to the model registry is made (M19)
30. Create a data storage in GCP Bucket for your data and link this with your data version control setup (M21)
31. Create a trigger workflow for automatically building your docker images (M21)
32. Get your model training in GCP using either the Engine or Vertex AI (M21)
33. Create a FastAPI application that can do inference using your model (M22)
34. Deploy your model in GCP using either Functions or Run as the backend (M23)
35. Write API tests for your application and setup continues integration for these (M24)
36. Load test your application (M24)
37. Create a more specialized ML-deployment API using either ONNX or BentoML, or both (M25)
38. Create a frontend for your API (M26)

Week 3 tasks

39. Check how robust your model is towards data drifting (M27)
40. Deploy to the cloud a drift detection API (M27)
41. Instrument your API with a couple of system metrics (M28)
42. Setup cloud monitoring of your instrumented application (M28)
43. Create one or more alert systems in GCP to alert you if your app is not behaving correctly (M28)
44. If applicable, optimize the performance of your data loading using distributed data loading (M29)
45. If applicable, optimize the performance of your training pipeline by using distributed training (M30)
46. Play around with quantization, compilation and pruning for you trained models to increase inference speed (M31)

Extra

47. Write some documentation for your application (M32)
48. Publish the documentation to GitHub Pages (M32)
49. Revisit your initial project description. Did the project turn out as you wanted?
50. Create an architectural diagram over your MLOps pipeline
51. Make sure all group members have an understanding about all parts of the project
52. Uploaded all your code to GitHub